{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bedaee8-709e-4884-a042-d6acbf0ac3d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2, ast\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "#import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random\n",
    "#from apex import amp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ab3474-0c25-42df-af19-2aa7db8813b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c56c23c-7b96-4c32-867c-54f531d727ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb08295d-4b64-4f88-b094-f3d108971433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>mask</th>\n",
       "      <th>hu_array</th>\n",
       "      <th>hu_array_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n",
       "      <td>[[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label1                                               mask  \\\n",
       "0    LR2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1    LR2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2    LR2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3    LR2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4    LR2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                            hu_array  \\\n",
       "0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "3  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "4  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       "\n",
       "                                        hu_array_old  \n",
       "0  [[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...  \n",
       "1  [[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...  \n",
       "2  [[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...  \n",
       "3  [[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...  \n",
       "4  [[-1024.0, -1024.0, -1024.0, -1024.0, -1024.0,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_pickle('lung_cancer_test.pkl')\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e897679-59f5-41a3-93ea-ba685a2c730b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"vgg11\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7bf96c9-f859-427b-a436-e0c82bb29ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): VGGEncoder(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (14): ReLU(inplace=True)\n",
       "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): CenterBlock(\n",
       "      (0): Conv2dReLU(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dReLU(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8730e4f5-973d-4f54-9aed-2d2c4dbe9c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_dice_coefficient(mask_true, mask_pred):\n",
    "    intersection = np.sum(mask_true * mask_pred)\n",
    "    union = np.sum(mask_true) + np.sum(mask_pred)\n",
    "    \n",
    "    dice_coefficient = (2.0 * intersection) / (union + 1e-8)  \n",
    "    \n",
    "    return dice_coefficient\n",
    "\n",
    "def precision_score(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_pixel_pred = np.sum(pred_mask)\n",
    "    precision = np.mean((intersect++ 1e-8)/(total_pixel_pred++ 1e-8))\n",
    "    return precision\n",
    "\n",
    "def recall_score(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_pixel_truth = np.sum(groundtruth_mask)\n",
    "    recall = np.mean((intersect+ 1e-8)/(total_pixel_truth+ 1e-8))\n",
    "    return recall\n",
    "\n",
    "def calculate_iou(mask_true, mask_pred):\n",
    "    intersection = np.sum(mask_true * mask_pred)\n",
    "    union = np.sum(mask_true) + np.sum(mask_pred) - intersection\n",
    "    \n",
    "    iou = (intersection + 1e-8) / (union + 1e-8)  \n",
    "    \n",
    "    return iou\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def hausdorff_distance(mask1, mask2):\n",
    "    # Получение координат точек в масках\n",
    "    coords_mask1 = np.transpose(np.nonzero(mask1))\n",
    "    coords_mask2 = np.transpose(np.nonzero(mask2))\n",
    "\n",
    "    # Вычисление расстояний между всеми точками в двух масках\n",
    "    distances_mask1_to_mask2 = cdist(coords_mask1, coords_mask2)\n",
    "    distances_mask2_to_mask1 = cdist(coords_mask2, coords_mask1)\n",
    "\n",
    "    # Нахождение максимального расстояния для каждой маски\n",
    "    max_distance_mask1 = np.max(np.min(distances_mask1_to_mask2, axis=1))\n",
    "    max_distance_mask2 = np.max(np.min(distances_mask2_to_mask1, axis=1))\n",
    "\n",
    "    # Вычисление дистанции Хаусдорфа\n",
    "    hausdorff_distance = max(max_distance_mask1, max_distance_mask2)\n",
    "\n",
    "    return hausdorff_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59592ca-0d56-4802-b571-7d5d0bfc93c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_evaluation(pretrained_weights, method_name):\n",
    "    model.load_state_dict(torch.load(pretrained_weights))\n",
    "    model.eval()\n",
    "    print('augmentation method name: ' + method_name)\n",
    "    d = []\n",
    "    iou = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    labels = val_df['label1'].unique()\n",
    "    for j in labels:\n",
    "        dices = []\n",
    "        test = val_df.loc[val_df['label1'] == j].reset_index(drop=True)\n",
    "        for i in range(len(test)):\n",
    "            #new_shape = [224,224]\n",
    "            mask = test['mask'][i]\n",
    "            img = test['hu_array'][i]\n",
    "            img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "            img = exposure.equalize_adapthist(img/np.max(img))\n",
    "            img = img.astype(np.float64)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = img.float()\n",
    "            img = img.cuda()\n",
    "            masks = mask.astype(int)\n",
    "            outputs = model(img)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            try:\n",
    "                mask_pred = (outputs.cpu().detach().numpy() >= 0.5) ** 2\n",
    "            except:\n",
    "                mask_pred = np.zeros([512,512])\n",
    "            dices.append(calculate_dice_coefficient(masks, mask_pred))\n",
    "            d.append(calculate_dice_coefficient(masks, mask_pred))\n",
    "            iou.append(calculate_iou(masks, mask_pred))\n",
    "            prec.append(precision_score(masks, mask_pred))\n",
    "            rec.append(recall_score(masks, mask_pred))\n",
    "        print(\"Dice for \" + j + \" \" + str(np.mean(dices))+\" \" +str(len(dices)))\n",
    "    print(\"Average\") \n",
    "    print(\"DICE \" + str(np.mean(d)))\n",
    "    print(\"IoU \" + str(np.mean(iou)))\n",
    "    print(\"precision \" + str(np.mean(prec)))\n",
    "    print(\"recall \"+str(np.mean(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b9fcd07-a04b-4011-9b1b-f85f2e79ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation method name: U-Net\n",
      "Dice for LR2 0.1166048928253063 35\n",
      "Dice for LR3 0.3952044555588205 37\n",
      "Dice for LR4A 0.3395490924691667 97\n",
      "Dice for LR4B 0.612629272338904 95\n",
      "Average\n",
      "DICE 0.41605976873586037\n",
      "IoU 0.3566316357515479\n",
      "precision 0.8112904057792768\n",
      "recall 0.4441356389658143\n"
     ]
    }
   ],
   "source": [
    "model_evaluation('U-Net with VGG/Netdataaug_12.pth','U-Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5092777-d01e-4c08-82d6-f8fc205a26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u-net",
   "language": "python",
   "name": "u-net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
